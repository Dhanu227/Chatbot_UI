# ğŸ§  AI Chat Assistant (FastAPI + LangChain + Ollama)

This is an AI-powered chatbot web app inspired by ChatGPT. It allows users to register, create sessions, and chat with an AI assistant powered by **LangChain + Ollama** using the **Mistral 7B** model â€” all running locally and open-source.

---

## ğŸš€ Features

- ğŸ” User registration & login (bcrypt-secured)
- ğŸ’¬ Multiple chat sessions per user 
- ğŸ§  AI responses using LangChain + Ollama (Mistral 7B or other models)
- ğŸ—ƒï¸ Persistent history stored in MySQL
- ğŸ’» Modern two-page UI (login & chat) with sidebar layout
- ğŸ§© Works 100% offline â€” no paid APIs

---

## ğŸ—ï¸ Tech Stack

| Layer          | Technology             |
|----------------|-------------------------|
| Frontend       | HTML, CSS, JavaScript   |
| Backend        | FastAPI (Python)        |
| AI Model       | LangChain + Ollama      |
| Database       | MySQL + SQLAlchemy ORM  |
| Authentication | Bcrypt                  |
| Server         | Uvicorn (ASGI)          |

---

## ğŸ“ Project Structure

CHATBOT_UI/
â”œâ”€â”€ api/                    # FastAPI app + static frontend
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ login.html
â”‚       â”œâ”€â”€ chat.html
â”‚       â””â”€â”€ script.js
â”œâ”€â”€ chatbot/                # Core logic: DB, LLM, sessions
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ session.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env                    # ğŸ” MySQL credentials (NOT committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py                 # CLI version (optional)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸ› ï¸ How to Run This Project Locally

1)To run this project locally, first clone the repository and move into the folder using:

```bash
git clone https://github.com/yourusername/chatbot-ui.git
cd chatbot-ui
Next, create a .env file in the root directory of your project and add your MySQL credentials:

2)env
MYSQL_USER=root
MYSQL_PASSWORD=yourpassword
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_DB=your_database_name
Now create a Python virtual environment and activate it:

3)bash
python -m venv venv
venv\Scripts\activate     # Windows
# or
source venv/bin/activate  # macOS/Linux

3)Then install the dependencies:
bash
pip install -r requirements.txt

4)Make sure you have Ollama installed. You can download it from https://ollama.com. Once installed, start the Ollama server in a separate terminal:
bash
ollama serve

Then pull the model you'll be using (e.g., mistral):
bash
ollama pull mistral

5)Now you can start the FastAPI server:
bash
uvicorn api.app:app --reload --port 8080

Finally, open your browser and go to:
http://localhost:8080

6)From here, you can register a new user, log in, create or select sessions from the sidebar, and begin chatting with the AI.
